{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necesseties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../assets/review_sentences_with_sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Make text lowercase, remove text in square brackets, remove links, remove HTML tags,\n",
    "remove punctuation, remove words containing numbers, remove all single characters, \n",
    "and substitute multiple spaces with single space.\n",
    "'''\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's a pretty good, inexpensive casual or busi...</td>\n",
       "      <td>1</td>\n",
       "      <td>its pretty good inexpensive casual or business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For example, it has no side pleats in back and...</td>\n",
       "      <td>0</td>\n",
       "      <td>for example it has no side pleats in back and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you do you'll be disappointed</td>\n",
       "      <td>2</td>\n",
       "      <td>if you do youll be disappointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is only noticeable to me and only because...</td>\n",
       "      <td>0</td>\n",
       "      <td>this is only noticeable to me and only because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Also, there are lots of loose threads from pro...</td>\n",
       "      <td>2</td>\n",
       "      <td>also there are lots of loose threads from prod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  \\\n",
       "0  It's a pretty good, inexpensive casual or busi...         1   \n",
       "1  For example, it has no side pleats in back and...         0   \n",
       "2                   If you do you'll be disappointed         2   \n",
       "3  This is only noticeable to me and only because...         0   \n",
       "4  Also, there are lots of loose threads from pro...         2   \n",
       "\n",
       "                                             cleaned  \n",
       "0  its pretty good inexpensive casual or business...  \n",
       "1  for example it has no side pleats in back and ...  \n",
       "2                    if you do youll be disappointed  \n",
       "3  this is only noticeable to me and only because...  \n",
       "4  also there are lots of loose threads from prod...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned'] = df['sentence'].apply(lambda x:clean_text(x))\n",
    "\n",
    "# delete row with missing values\n",
    "df['cleaned'].replace('', np.nan, inplace=True)\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for words in df['cleaned']:\n",
    "    corpus.append(words.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(corpus, size = 64, min_count = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Mean of Word Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors(document_list):\n",
    "    document_embedding_list = []\n",
    "\n",
    "    for line in document_list:\n",
    "        doc2vec = None\n",
    "        count = 0\n",
    "        for word in line.split():\n",
    "            if word in word2vec_model.wv.vocab:\n",
    "                count += 1\n",
    "                # Add vector values of all words in the document\n",
    "                if doc2vec is None:\n",
    "                    doc2vec = word2vec_model[word]\n",
    "                else:\n",
    "                    doc2vec = doc2vec + word2vec_model[word]\n",
    "\n",
    "        if doc2vec is not None:\n",
    "            # Divide the vector of all the word vectors by the length of the document\n",
    "            doc2vec = doc2vec / count\n",
    "            document_embedding_list.append(doc2vec)\n",
    "\n",
    "    # Returns a list of document vectors for each document\n",
    "    return document_embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of keywords you want to analyze in detail\n",
    "keywords = ['fit', 'color', 'material']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-f6b31b54aaec>:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  doc2vec = word2vec_model[word]\n",
      "<ipython-input-7-f6b31b54aaec>:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  doc2vec = doc2vec + word2vec_model[word]\n"
     ]
    }
   ],
   "source": [
    "keyword_embedding_list = vectors(keywords)\n",
    "document_embedding_list = vectors(df['cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Most Relevant Reviews by Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = cosine_similarity(keyword_embedding_list, document_embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def most_relevant_review(review_num):\n",
    "    for keyword_index in range(len(keywords)):\n",
    "        sim_scores = list(enumerate(cosine_similarities[keyword_index]))\n",
    "        sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "        sim_scores = sim_scores[0:review_num]\n",
    "\n",
    "        # indices of most relevant reviews\n",
    "        indices = [i[0] for i in sim_scores]\n",
    "        \n",
    "        keyword = keywords[keyword_index]\n",
    "        keyword_reviews = []\n",
    "        for index in indices:\n",
    "            review = dict()\n",
    "            review['id'] = index\n",
    "            review['sentence'] = df['sentence'].iloc[index]\n",
    "            review['sentiment'] = df['sentiment'].iloc[index]\n",
    "            keyword_reviews.append(review)\n",
    "            \n",
    "        relevant_reviews[keyword] = keyword_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_reviews = dict()\n",
    "most_relevant_review(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit': [{'id': 9469, 'sentence': 'He is 16 and 6 foot 3, so if you are ordering for someone tall be cautious', 'sentiment': '0'}, {'id': 9946, 'sentence': 'Fit great', 'sentiment': '1'}, {'id': 10509, 'sentence': 'The shirt fits Perfect', 'sentiment': '1'}, {'id': 10882, 'sentence': 'remember to size up to make a shirt not feel skin tight 2-3\" for tighter fit, 4 - 5 regular fit, 6+ baggy', 'sentiment': '0'}, {'id': 14050, 'sentence': 'but i have never bought a shirt that fits this well', 'sentiment': '1'}], 'color': [{'id': 1427, 'sentence': 'Great shirt - bought it for my husband for a wedding, it wasn_ see-thru and a great color', 'sentiment': '1'}, {'id': 5970, 'sentence': 'Great purchase, materials great, husband is very happy', 'sentiment': '1'}, {'id': 6786, 'sentence': \"It's a little tight in the chest\", 'sentiment': '2'}, {'id': 252, 'sentence': 'This is a really nice looking shirt', 'sentiment': '1'}, {'id': 10930, 'sentence': \"It's a regular fabric dressy shirt with a denim look to it\", 'sentiment': '0'}], 'material': [{'id': 2386, 'sentence': 'Quality feel', 'sentiment': '1'}, {'id': 8837, 'sentence': 'Very comfortable, easy to wash with minimal ironing', 'sentiment': '1'}, {'id': 9432, 'sentence': 'Its ok', 'sentiment': '1'}, {'id': 7988, 'sentence': 'Did not like material', 'sentiment': '2'}, {'id': 11435, 'sentence': 'Fabric is kinda thick', 'sentiment': '0'}]}\n"
     ]
    }
   ],
   "source": [
    "print(relevant_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save into json\n",
    "with open('./relevant_reviews.json', 'w', encoding='utf-8') as make_file:\n",
    "    json.dump(relevant_reviews, make_file, indent=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}